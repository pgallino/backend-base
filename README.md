# ğŸ§© backend-base â€” Plantilla profesional para APIs con FastAPI y SQLAlchemy

> **Arquitectura hexagonal (Ports & Adapters) Â· Base de datos integrada Â· Migraciones Alembic Â· Tests BDD y CI/CD listos**

<p align="center">
  <img src="https://img.shields.io/badge/python-3.11%2B-blue" alt="Python version" />
  <img src="https://img.shields.io/badge/FastAPI-0.115%2B-009688?logo=fastapi" alt="FastAPI" />
  <img src="https://img.shields.io/badge/SQLAlchemy-async-orange?logo=python" alt="SQLAlchemy async" />
  <img src="https://img.shields.io/badge/Alembic-migrations-yellow" alt="Alembic" />
  <img src="https://img.shields.io/badge/tests-pytest%20%2B%20BDD-green?logo=pytest" alt="Testing" />
  <img src="https://img.shields.io/badge/docker-ready-2496ED?logo=docker" alt="Docker" />
<img src="https://github.com/pgallino/backend-base/actions/workflows/main.yml/badge.svg?branch=main" alt="GitHub Actions CI" />
  <img src="https://img.shields.io/badge/license-MIT-lightgrey" alt="License MIT" />
</p>

---

## ğŸ“š Ãndice

1. [Resumen](#-resumen)
2. [Arquitectura](#-arquitectura)
3. [Estructura del proyecto](#-estructura-del-proyecto)
4. [Requisitos y stack](#-requisitos-y-stack)
5. [ConfiguraciÃ³n y entorno](#-configuraciÃ³n-y-entorno)
6. [Base de datos y migraciones](#-base-de-datos-y-migraciones)
7. [EjecuciÃ³n en desarrollo](#-ejecuciÃ³n-en-desarrollo)
8. [Pruebas (TDD y BDD)](#-pruebas-tdd-y-bdd)
9. [Makefile y comandos Ãºtiles](#-makefile-y-comandos-Ãºtiles)
10. [CI/CD y despliegue](#-cicd-y-despliegue)
11. [ReutilizaciÃ³n y buenas prÃ¡cticas](#-reutilizaciÃ³n-y-buenas-prÃ¡cticas)

---

## ğŸš€ Resumen

`backend-base` es una plantilla profesional para construir **backends escalables en Python**, con **FastAPI**, **SQLAlchemy asÃ­ncrono** y **Alembic** para la gestiÃ³n de base de datos.

Sigue los principios de **Arquitectura Hexagonal (Ports & Adapters)**, garantizando una separaciÃ³n clara entre dominio, infraestructura y orquestaciÃ³n.

Incluye configuraciÃ³n lista para **tests unitarios y de aceptaciÃ³n (BDD)**, y ejemplos de **despliegue con Docker, Render y AWS**.

### ğŸ¯ Objetivo
Proporcionar una base sÃ³lida, extensible y educativa para proyectos reales, enfocada en:

- DiseÃ±o limpio y mantenible (DDD + Hexagonal)
- Tests integrados desde el inicio (unit + BDD)
- ConfiguraciÃ³n y despliegue reproducibles con Docker
- SeparaciÃ³n clara entre dominio, adaptadores y orquestaciÃ³n

---

## ğŸ§± Arquitectura

El proyecto implementa una **Arquitectura Hexagonal (Ports & Adapters)**, donde cada capa tiene una responsabilidad bien definida.

```text
Cliente HTTP
   â†“
[Adaptador de entrada] â€” FastAPI (rutas, validaciÃ³n Pydantic)
   â†“
[Fachada de aplicaciÃ³n] â€” coordina lÃ³gica de dominio y persistencia
   â†“
[Dominio] â€” entidades y servicios puros de negocio
   â†“
[Adaptador de salida] â€” repositorios SQLAlchemy async
   â†“
Base de datos (SQLite / Postgres)
```

### Capas principales

- **Adaptadores de entrada:** reciben peticiones HTTP, validan con Pydantic y delegan a la fachada.
- **Fachada de aplicaciÃ³n:** orquesta la interacciÃ³n entre dominio y repositorios.
- **Dominio:** contiene entidades y reglas de negocio puras, sin dependencias externas.
- **Adaptadores de salida:** implementan la persistencia mediante SQLAlchemy async.
- **Infraestructura:** configuraciÃ³n, migraciones, logging, etc.

Esta separaciÃ³n facilita el testing, la evoluciÃ³n del cÃ³digo y la independencia del framework o base de datos.

---

## ğŸ—‚ï¸ Estructura del proyecto

```bash
src/
â”œâ”€â”€ app.py                  # Punto de entrada (FastAPI)
â”œâ”€â”€ config.py               # ConfiguraciÃ³n central
â”œâ”€â”€ adapters/
â”‚   â”œâ”€â”€ api/                # Endpoints + fachada
â”‚   â””â”€â”€ db/                 # Modelos y repositorios SQLAlchemy
â”œâ”€â”€ domain/                 # Entidades y servicios de dominio
alembic/                    # Migraciones de esquema
tests/                      # Tests unitarios y BDD
```

---

## ğŸ’» Requisitos y stack

- Python **3.11+** (preparado para 3.12)
- **FastAPI** â€” framework principal
- **SQLAlchemy async** â€” ORM asÃ­ncrono
- **Alembic** â€” migraciones de base de datos
- **pytest + pytest-bdd** â€” testing unitario y de aceptaciÃ³n
- **Docker Compose** â€” entorno reproducible
- **GitHub Actions** â€” CI/CD de ejemplo

---

## âš™ï¸ ConfiguraciÃ³n y entorno

El proyecto usa un archivo `.env` para variables de entorno. Ejemplo (`.env.example`):

```bash
ENVIRONMENT=dev
PORT=8000
DB_URL_SYNC=sqlite:///dev.db
DB_URL_ASYNC=sqlite+aiosqlite:///dev.db
ALLOWED_ORIGINS=http://localhost:3000
SECRET_KEY=super-secret-key
```

> âš ï¸ **No subas secretos reales al repositorio.** Usa secrets en CI/CD o servicios como Render o AWS.

---

## ğŸ—„ï¸ Base de datos y migraciones

Alembic se utiliza para versionar el esquema de la base de datos.

### Alembic

Alembic es la herramienta de migrations para SQLAlchemy: permite crear "revisiones" que describen cambios en el esquema (crear tablas, columnas, Ã­ndices) y aplicarlas de forma ordenada en cualquier entorno. En este proyecto usamos Alembic para mantener el historial del esquema y aplicarlo en CI / despliegues.

Hemos aÃ±adido objetivos en el `Makefile` para envolver Alembic y simplificar el flujo. Usa los objetivos `make` desde tu mÃ¡quina o dentro del contenedor:

```bash
# Inicializar (solo la primera vez en un repo nuevo):
make alembic-init

# Crear una nueva migraciÃ³n (autogenerate + archivo en alembic/versions):
make alembic-migrate

# Aplicar migraciones (upgrade hasta head):
make alembic-upgrade

# Deshacer la Ãºltima migraciÃ³n (downgrade -1):
make alembic-downgrade
```

Usar `make` garantiza que `PYTHONPATH` y el contexto de ejecuciÃ³n estÃ©n correctamente definidos para que Alembic encuentre el mÃ³dulo `src`.

### Variables relevantes

- `DB_URL_SYNC` â€” URL sincrÃ³nica (usada por Alembic)
- `DB_URL_ASYNC` â€” URL asÃ­ncrona (usada por la app)

Nota: Alembic requiere un driver sincrÃ³nico; la app usa un driver asÃ­ncrono (ej: `postgresql+asyncpg://`). En CI y despliegue define ambas variables de entorno segÃºn corresponda.

---

## ğŸ§‘â€ğŸ’» EjecuciÃ³n en desarrollo

Con **Docker Compose** (recomendado):

```bash
# Levantar servicios
make up

# Entrar al contenedor
make shell
```

Sin Docker:

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn src.app:app --reload
```

---

## ğŸ§ª Pruebas (TDD y BDD)

El proyecto incluye **tests unitarios y de aceptaciÃ³n**.

### Estructura

```
tests/
â”œâ”€â”€ domain/           # Tests unitarios (lÃ³gica pura)
â””â”€â”€ acceptance/       # Tests BDD (pytest-bdd + Gherkin)
```

### Comandos

```bash
make test            # Ejecuta todos los tests
make test-unit       # Solo tests unitarios
make test-acceptance # Solo tests BDD
```

> Las pruebas BDD usan `TestClient` de FastAPI y se ejecutan sin servidor externo.

Detalles prÃ¡cticos sobre `TestClient` y los acceptance tests

- QuÃ© hace `TestClient`: monta la aplicaciÃ³n ASGI (FastAPI) en memoria y permite hacer peticiones HTTP a la app desde pytest sin necesidad de arrancar un proceso externo. Esto habilita pruebas rÃ¡pidas e independientes del entorno.

- Inicio y eventos de aplicaciÃ³n: `TestClient` dispara los eventos de `startup` y `shutdown` de FastAPI, por lo que cualquier inicializaciÃ³n (conexiÃ³n a DB en tests, carga de fixtures) definida en el `lifespan` o `startup` se ejecuta automÃ¡ticamente.

- Fixtures y preparaciÃ³n de la DB: en `tests/acceptance/conftest.py` hay fixtures que crean/aseguran las tablas, limpian filas entre escenarios y reinician secuencias (SQLite). AsegÃºrate de que las fixtures hagan _arranque limpio_ (crear tablas si hace falta y truncar) para que cada escenario sea determinista.

- CÃ³mo ejecutar los acceptance tests:

```bash
# desde el host (usa las variables de entorno del entorno de desarrollo):
make test-acceptance

# ejecutar un escenario o un conjunto especifico (mÃ¡s verboso):
pytest tests/acceptance -k "herramientas" -s -vv
```

- Ejecutar dentro del contenedor (recomendado para reproducibilidad):

```bash
make shell        # levanta y entra al contenedor
# dentro del contenedor:
make test-acceptance
```

Con esto las pruebas BDD permanecen rÃ¡pidas, deterministas y fÃ¡ciles de ejecutar tanto en tu mÃ¡quina como en CI.

---

## ğŸ§° Makefile y comandos Ãºtiles

| Comando | DescripciÃ³n |
|----------|--------------|
| `make up` | Construye y levanta contenedores |
| `make down` | Detiene y elimina servicios |
| `make test` | Ejecuta toda la suite de tests |
| `make format` | Formatea el cÃ³digo con black/isort |
| `make lint` | Ejecuta linters y type-checks |
| `make check` | Corre `format-check` + `lint` |
| `make shell` | Abre una shell en el contenedor backend |

---

## â˜ï¸ CI/CD y despliegue

Esta plantilla incluye workflows de ejemplo en `.github/workflows/` y patrones recomendados para desplegar en Render, AWS (App Runner/ECS) o usando Neon como base de datos.

### Neon (Postgres serverless)

- Define en GitHub Secrets la URL de Neon. En este proyecto conviene publicar ambas variantes segÃºn uso:
   - `DB_URL_ASYNC` â€” p. ej. `postgresql+asyncpg://user:pass@host/db` (usada por la app FastAPI)
   - `DB_URL_SYNC` â€” p. ej. `postgresql+psycopg2://user:pass@host/db` (Ãºtil para ejecutar Alembic desde un job/contenedor sync)

### AWS (ECR + App Runner)

Los workflows de despliegue en este repositorio ya se encargan de ejecutar las migraciones en Neon antes de promover la nueva versiÃ³n, por lo que no es necesario ejecutar migraciones manualmente durante el despliegue. Para desplegar en AWS normalmente sÃ³lo necesitas construir y subir la imagen a ECR, configurar el servicio App Runner y asegurarte de que los secrets/variables estÃ©n presentes en GitHub Actions o en el entorno de ejecuciÃ³n.

Variables/Secrets clave en AWS:

- `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `ECR_REPOSITORY`
- `DB_URL_ASYNC`, `SECRET_KEY`, `ALLOWED_ORIGINS`


### Render

El pipeline de despliegue de este repositorio invoca el workflow de migraciones en Neon, de modo que no es necesario ejecutar comandos de migraciÃ³n manualmente en Render. Configura el servicio en Render para que use la imagen que publica el workflow y aÃ±ade los secrets/variables necesarios.

Variables/Secrets a configurar en Render:

- `RENDER_API_KEY`, `RENDER_SERVICE_ID`, `DB_URL_ASYNC`, `ALLOWED_ORIGINS`

### GitHub Actions

Workflows incluidos (ejemplos):

- `main.yml` â€” checks y tests (`make check`, `make test`).
- `deploy-render.yml` â€” ejemplo para disparar un deploy en Render.
- `deploy-aws.yml` â€” ejemplo para build/push a ECR y despliegue;

Nota importante: los workflows estÃ¡n listos como ejemplos; para que funcionen define los secrets mencionados en Settings â†’ Secrets. En este repositorio los pipelines de despliegue ya invocan el workflow de migraciones (`deploy-neon.yml`) y por tanto las migraciones se ejecutan automÃ¡ticamente contra Neon durante el proceso de despliegue â€” no hace falta ejecutarlas manualmente. AsegÃºrate de que `DB_URL_SYNC`/`DB_URL_ASYNC` y demÃ¡s secrets estÃ©n definidos en GitHub Actions para que el job de migraciones pueda conectarse a Neon.

### Secrets a crear (copia/pega)

A continuaciÃ³n tienes una tabla con los secrets y variables que aparecen en los workflows; crea estos secrets en GitHub (Settings â†’ Secrets and variables â†’ Actions) y configura las variables de entorno equivalentes en tu proveedor (Render, ECS, App Runner) para runtime:

| Secret / Variable | Usado por | DescripciÃ³n |
|---|---|---|
| NEON_DB_SYNC | `deploy-neon.yml` (job `migrate`) | URL sÃ­ncrona de Neon (ej. `postgresql+psycopg2://user:pass@host:port/db`) â€” usada por Alembic en el job de migraciones |
| DB_URL_ASYNC | runtime (Render / ECS / App Runner) | URL asÃ­ncrona para la app FastAPI (ej. `postgresql+asyncpg://user:pass@host/db`) |
| DB_URL_SYNC | (opcional) runtime / CI | Variante sÃ­ncrona si alguna tarea la necesita en runtime; `NEON_DB_SYNC` se pasa a los workflows para migraciones |
| AWS_ACCESS_KEY_ID | `deploy-aws.yml` | Credencial AWS (user con permisos ECR/Push) |
| AWS_SECRET_ACCESS_KEY | `deploy-aws.yml` | Credencial AWS |
| AWS_ACCOUNT_ID | `deploy-aws.yml` | ID de la cuenta AWS (usado para tag de la imagen) |
| ECR_REPOSITORY | `deploy-aws.yml` | Nombre del repositorio en ECR (se puede dejar en env del workflow) |
| RENDER_API_KEY | `deploy-render.yml` | API key para la cuenta Render (usar secret) |
| RENDER_SERVICE_ID | `deploy-render.yml` | ID del servicio en Render que se va a desplegar |
| RENDER_URL | `deploy-render.yml` | URL pÃºblica para health-check (opcional; usada por el workflow) |
| SECRET_KEY | runtime | Clave secreta de la aplicaciÃ³n (runtime) |
| ALLOWED_ORIGINS | runtime | OrÃ­genes permitidos para CORS (runtime) |

> Nota: `NEON_DB_SYNC` es el secret requerido por `deploy-neon.yml` y el workflow lo exporta como `DB_URL_SYNC` para ejecutar `make alembic-upgrade`. `DB_URL_ASYNC` debe establecerse en el entorno del servicio para que la app use el driver asÃ­ncrono en producciÃ³n.

---

## â™»ï¸ ReutilizaciÃ³n y buenas prÃ¡cticas

La arquitectura estÃ¡ pensada para ser **reutilizable y desacoplada**:

- El **dominio** y la **fachada** no dependen de frameworks.
- Se puede cambiar la base de datos sin modificar la lÃ³gica de negocio.
- Permite testear el dominio de forma aislada.
- Facilita extender a otros tipos de adaptadores (gRPC, CLI, eventos, etc.).

> MantÃ©n las entidades puras, define interfaces en el dominio y deja las implementaciones en `adapters/`.

---

ğŸ“˜ **Con esta plantilla tendrÃ¡s un backend modular, testeable y preparado para producciÃ³n, sin sacrificar claridad ni mantenibilidad.**
