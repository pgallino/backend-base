# üß© backend-base ‚Äî Plantilla profesional para APIs con FastAPI y SQLAlchemy

> **Arquitectura hexagonal (Ports & Adapters) ¬∑ Base de datos integrada ¬∑ Migraciones Alembic ¬∑ Tests BDD y CI/CD listos**

<p align="center">
  <img src="https://img.shields.io/badge/python-3.11%2B-blue" alt="Python version" />
  <img src="https://img.shields.io/badge/FastAPI-0.115%2B-009688?logo=fastapi" alt="FastAPI" />
  <img src="https://img.shields.io/badge/SQLAlchemy-async-orange?logo=python" alt="SQLAlchemy async" />
  <img src="https://img.shields.io/badge/Alembic-migrations-yellow" alt="Alembic" />
  <img src="https://img.shields.io/badge/tests-pytest%20%2B%20BDD-green?logo=pytest" alt="Testing" />
  <img src="https://img.shields.io/badge/docker-ready-2496ED?logo=docker" alt="Docker" />
<img src="https://github.com/pgallino/backend-base/actions/workflows/main.yml/badge.svg?branch=main" alt="GitHub Actions CI" />
  <img src="https://img.shields.io/badge/license-MIT-lightgrey" alt="License MIT" />
</p>

---

## üìö √çndice

1. [Resumen](#-resumen)
2. [Arquitectura](#-arquitectura)
3. [Estructura del proyecto](#-estructura-del-proyecto)
4. [Requisitos y stack](#-requisitos-y-stack)
5. [Configuraci√≥n y entorno](#-configuraci√≥n-y-entorno)
6. [Base de datos y migraciones](#-base-de-datos-y-migraciones)
7. [Ejecuci√≥n en desarrollo](#-ejecuci√≥n-en-desarrollo)
8. [Pruebas (TDD y BDD)](#-pruebas-tdd-y-bdd)
9. [Makefile y comandos √∫tiles](#-makefile-y-comandos-√∫tiles)
10. [CI/CD y despliegue](#-cicd-y-despliegue)
11. [Reutilizaci√≥n y buenas pr√°cticas](#-reutilizaci√≥n-y-buenas-pr√°cticas)

---

## üöÄ Resumen

`backend-base` es una plantilla profesional para construir **backends escalables en Python**, con **FastAPI**, **SQLAlchemy as√≠ncrono** y **Alembic** para la gesti√≥n de base de datos.

Sigue los principios de **Arquitectura Hexagonal (Ports & Adapters)**, garantizando una separaci√≥n clara entre dominio, infraestructura y orquestaci√≥n.

Incluye configuraci√≥n lista para **tests unitarios y de aceptaci√≥n (BDD)**, y ejemplos de **despliegue con Docker, Render y AWS**.

### üéØ Objetivo
Proporcionar una base s√≥lida, extensible y educativa para proyectos reales, enfocada en:

- Dise√±o limpio y mantenible (DDD + Hexagonal)
- Tests integrados desde el inicio (unit + BDD)
- Configuraci√≥n y despliegue reproducibles con Docker
- Separaci√≥n clara entre dominio, adaptadores y orquestaci√≥n

---

## üß± Arquitectura

El proyecto implementa una **Arquitectura Hexagonal (Ports & Adapters)**, donde cada capa tiene una responsabilidad bien definida.

```text
Cliente HTTP
   ‚Üì
[Adaptador de entrada] ‚Äî FastAPI (rutas, validaci√≥n Pydantic)
   ‚Üì
[Fachada de aplicaci√≥n] ‚Äî coordina l√≥gica de dominio y persistencia
   ‚Üì
[Dominio] ‚Äî entidades y servicios puros de negocio
   ‚Üì
[Adaptador de salida] ‚Äî repositorios SQLAlchemy async
   ‚Üì
Base de datos (SQLite / Postgres)
```

### Capas principales

- **Adaptadores de entrada:** reciben peticiones HTTP, validan con Pydantic y delegan a la fachada.
- **Fachada de aplicaci√≥n:** orquesta la interacci√≥n entre dominio y repositorios.
- **Dominio:** contiene entidades y reglas de negocio puras, sin dependencias externas.
- **Adaptadores de salida:** implementan la persistencia mediante SQLAlchemy async.
- **Infraestructura:** configuraci√≥n, migraciones, logging, etc.

Esta separaci√≥n facilita el testing, la evoluci√≥n del c√≥digo y la independencia del framework o base de datos.

---

## üóÇÔ∏è Estructura del proyecto

```bash
src/
‚îú‚îÄ‚îÄ app.py                  # Punto de entrada (FastAPI)
‚îú‚îÄ‚îÄ config.py               # Configuraci√≥n central
‚îú‚îÄ‚îÄ adapters/
‚îÇ   ‚îú‚îÄ‚îÄ api/                # Endpoints + fachada
‚îÇ   ‚îî‚îÄ‚îÄ db/                 # Modelos y repositorios SQLAlchemy
‚îú‚îÄ‚îÄ domain/                 # Entidades y servicios de dominio
alembic/                    # Migraciones de esquema
tests/                      # Tests unitarios y BDD
```

---

## üíª Requisitos y stack

- Python **3.11+** (preparado para 3.12)
- **FastAPI** ‚Äî framework principal
- **SQLAlchemy async** ‚Äî ORM as√≠ncrono
- **Alembic** ‚Äî migraciones de base de datos
- **pytest + pytest-bdd** ‚Äî testing unitario y de aceptaci√≥n
- **Docker Compose** ‚Äî entorno reproducible
- **GitHub Actions** ‚Äî CI/CD de ejemplo

---

## ‚öôÔ∏è Configuraci√≥n y entorno

El proyecto usa un archivo `.env` para variables de entorno. Ejemplo (`.env.example`):

```bash
ENVIRONMENT=dev
PORT=8000
DB_URL_SYNC=sqlite:///dev.db
DB_URL_ASYNC=sqlite+aiosqlite:///dev.db
ALLOWED_ORIGINS=http://localhost:3000
SECRET_KEY=super-secret-key
```

> ‚ö†Ô∏è **No subas secretos reales al repositorio.** Usa secrets en CI/CD o servicios como Render o AWS.

---

## üóÑÔ∏è Base de datos y migraciones

Alembic se utiliza para versionar el esquema de la base de datos.

### Alembic

Alembic es la herramienta de migrations para SQLAlchemy: permite crear "revisiones" que describen cambios en el esquema (crear tablas, columnas, √≠ndices) y aplicarlas de forma ordenada en cualquier entorno. En este proyecto usamos Alembic para mantener el historial del esquema y aplicarlo en CI / despliegues.

Hemos a√±adido objetivos en el `Makefile` para envolver Alembic y simplificar el flujo. Usa los objetivos `make` desde tu m√°quina o dentro del contenedor:

```bash
# Inicializar (solo la primera vez en un repo nuevo):
make alembic-init

# Crear una nueva migraci√≥n (autogenerate + archivo en alembic/versions):
make alembic-migrate

# Aplicar migraciones (upgrade hasta head):
make alembic-upgrade

# Deshacer la √∫ltima migraci√≥n (downgrade -1):
make alembic-downgrade
```

Usar `make` garantiza que `PYTHONPATH` y el contexto de ejecuci√≥n est√©n correctamente definidos para que Alembic encuentre el m√≥dulo `src`.

### Variables relevantes

- `DB_URL_SYNC` ‚Äî URL sincr√≥nica (usada por Alembic)
- `DB_URL_ASYNC` ‚Äî URL as√≠ncrona (usada por la app)

Nota: Alembic requiere un driver sincr√≥nico; la app usa un driver as√≠ncrono (ej: `postgresql+asyncpg://`). En CI y despliegue define ambas variables de entorno seg√∫n corresponda.

---

## üßë‚Äçüíª Ejecuci√≥n en desarrollo

Con **Docker Compose** (recomendado):

```bash
# Levantar servicios
make up

# Entrar al contenedor
make shell
```

Sin Docker:

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn src.app:app --reload
```

---

## üß™ Pruebas (TDD y BDD)

El proyecto incluye **tests unitarios y de aceptaci√≥n**.

### Estructura

```
tests/
‚îú‚îÄ‚îÄ domain/           # Tests unitarios (l√≥gica pura)
‚îî‚îÄ‚îÄ acceptance/       # Tests BDD (pytest-bdd + Gherkin)
```

### Comandos

```bash
make test            # Ejecuta todos los tests
make test-unit       # Solo tests unitarios
make test-acceptance # Solo tests BDD
```

> Las pruebas BDD usan `TestClient` de FastAPI y se ejecutan sin servidor externo.

Detalles pr√°cticos sobre `TestClient` y los acceptance tests

- Qu√© hace `TestClient`: monta la aplicaci√≥n ASGI (FastAPI) en memoria y permite hacer peticiones HTTP a la app desde pytest sin necesidad de arrancar un proceso externo. Esto habilita pruebas r√°pidas e independientes del entorno.

- Inicio y eventos de aplicaci√≥n: `TestClient` dispara los eventos de `startup` y `shutdown` de FastAPI, por lo que cualquier inicializaci√≥n (conexi√≥n a DB en tests, carga de fixtures) definida en el `lifespan` o `startup` se ejecuta autom√°ticamente.

- Fixtures y preparaci√≥n de la DB: en `tests/acceptance/conftest.py` hay fixtures que crean/aseguran las tablas, limpian filas entre escenarios y reinician secuencias (SQLite). Aseg√∫rate de que las fixtures hagan _arranque limpio_ (crear tablas si hace falta y truncar) para que cada escenario sea determinista.

- C√≥mo ejecutar los acceptance tests:

```bash
# desde el host (usa las variables de entorno del entorno de desarrollo):
make test-acceptance

# ejecutar un escenario o un conjunto especifico (m√°s verboso):
pytest tests/acceptance -k "herramientas" -s -vv
```

- Ejecutar dentro del contenedor (recomendado para reproducibilidad):

```bash
make shell        # levanta y entra al contenedor
# dentro del contenedor:
make test-acceptance
```

Con esto las pruebas BDD permanecen r√°pidas, deterministas y f√°ciles de ejecutar tanto en tu m√°quina como en CI.

---

## üß∞ Makefile y comandos √∫tiles

| Comando | Descripci√≥n |
|----------|--------------|
| `make up` | Construye y levanta contenedores |
| `make down` | Detiene y elimina servicios |
| `make test` | Ejecuta toda la suite de tests |
| `make format` | Formatea el c√≥digo con black/isort |
| `make lint` | Ejecuta linters y type-checks |
| `make check` | Corre `format-check` + `lint` |
| `make shell` | Abre una shell en el contenedor backend |

---

## ‚òÅÔ∏è CI/CD y despliegue

Esta plantilla incluye workflows de ejemplo en `.github/workflows/` y patrones recomendados para desplegar en Render, AWS (App Runner/ECS) o usando Neon como base de datos.

### Neon (Postgres serverless)

- Define en GitHub Secrets la URL de Neon. En este proyecto conviene publicar ambas variantes seg√∫n uso:
   - `DB_URL_ASYNC` ‚Äî p. ej. `postgresql+asyncpg://user:pass@host/db` (usada por la app FastAPI)
   - `DB_URL_SYNC` ‚Äî p. ej. `postgresql+psycopg2://user:pass@host/db` (√∫til para ejecutar Alembic desde un job/contenedor sync)

### AWS (ECR + App Runner)

Los workflows de despliegue en este repositorio ya se encargan de ejecutar las migraciones en Neon antes de promover la nueva versi√≥n, por lo que no es necesario ejecutar migraciones manualmente durante el despliegue. Para desplegar en AWS normalmente s√≥lo necesitas construir y subir la imagen a ECR, configurar el servicio App Runner y asegurarte de que los secrets/variables est√©n presentes en GitHub Actions o en el entorno de ejecuci√≥n.

Variables/Secrets clave en AWS:

- `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `ECR_REPOSITORY`
- `DB_URL_ASYNC`, `SECRET_KEY`, `ALLOWED_ORIGINS`


### Render

El pipeline de despliegue de este repositorio invoca el workflow de migraciones en Neon, de modo que no es necesario ejecutar comandos de migraci√≥n manualmente en Render. Configura el servicio en Render para que use la imagen que publica el workflow y a√±ade los secrets/variables necesarios.

Variables/Secrets a configurar en Render:

- `RENDER_API_KEY`, `RENDER_SERVICE_ID`, `DB_URL_ASYNC`, `ALLOWED_ORIGINS`

### GitHub Actions

Workflows incluidos (ejemplos):

- `main.yml` ‚Äî checks y tests (`make check`, `make test`).
- `deploy-render.yml` ‚Äî ejemplo para disparar un deploy en Render.
- `deploy-aws.yml` ‚Äî ejemplo para build/push a ECR y despliegue;

Nota importante: los workflows est√°n listos como ejemplos; para que funcionen define los secrets mencionados en Settings ‚Üí Secrets. En este repositorio los pipelines de despliegue ya invocan el workflow de migraciones (`deploy-neon.yml`) y por tanto las migraciones se ejecutan autom√°ticamente contra Neon durante el proceso de despliegue ‚Äî no hace falta ejecutarlas manualmente. Aseg√∫rate de que `DB_URL_SYNC`/`DB_URL_ASYNC` y dem√°s secrets est√©n definidos en GitHub Actions para que el job de migraciones pueda conectarse a Neon.

### Secrets a crear (copia/pega)

A continuaci√≥n tienes una tabla con los secrets y variables que aparecen en los workflows; crea estos secrets en GitHub (Settings ‚Üí Secrets and variables ‚Üí Actions) y configura las variables de entorno equivalentes en tu proveedor (Render, ECS, App Runner) para runtime:

| Secret / Variable | Usado por | Descripci√≥n |
|---|---|---|
| NEON_DB_SYNC | `deploy-neon.yml` (job `migrate`) | URL s√≠ncrona de Neon (ej. `postgresql+psycopg2://user:pass@host:port/db`) ‚Äî usada por Alembic en el job de migraciones |
| DB_URL_ASYNC | runtime (Render / ECS / App Runner) | URL as√≠ncrona para la app FastAPI (ej. `postgresql+asyncpg://user:pass@host/db`) |
| DB_URL_SYNC | (opcional) runtime / CI | Variante s√≠ncrona si alguna tarea la necesita en runtime; `NEON_DB_SYNC` se pasa a los workflows para migraciones |
| AWS_ACCESS_KEY_ID | `deploy-aws.yml` | Credencial AWS (user con permisos ECR/Push) |
| AWS_SECRET_ACCESS_KEY | `deploy-aws.yml` | Credencial AWS |
| AWS_ACCOUNT_ID | `deploy-aws.yml` | ID de la cuenta AWS (usado para tag de la imagen) |
| ECR_REPOSITORY | `deploy-aws.yml` | Nombre del repositorio en ECR (se puede dejar en env del workflow) |
| RENDER_API_KEY | `deploy-render.yml` | API key para la cuenta Render (usar secret) |
| RENDER_SERVICE_ID | `deploy-render.yml` | ID del servicio en Render que se va a desplegar |
| RENDER_URL | `deploy-render.yml` | URL p√∫blica para health-check (opcional; usada por el workflow) |
| SECRET_KEY | runtime | Clave secreta de la aplicaci√≥n (runtime) |
| ALLOWED_ORIGINS | runtime | Or√≠genes permitidos para CORS (runtime) |

> Nota: `NEON_DB_SYNC` es el secret requerido por `deploy-neon.yml` y el workflow lo exporta como `DB_URL_SYNC` para ejecutar `make alembic-upgrade`. `DB_URL_ASYNC` debe establecerse en el entorno del servicio para que la app use el driver as√≠ncrono en producci√≥n.

---

## ‚ôªÔ∏è Reutilizaci√≥n y buenas pr√°cticas

La arquitectura est√° pensada para ser **reutilizable y desacoplada**:

- El **dominio** y la **fachada** no dependen de frameworks.
- Se puede cambiar la base de datos sin modificar la l√≥gica de negocio.
- Permite testear el dominio de forma aislada.
- Facilita extender a otros tipos de adaptadores (gRPC, CLI, eventos, etc.).

> Mant√©n las entidades puras, define interfaces en el dominio y deja las implementaciones en `adapters/`.

---

üìò **Con esta plantilla tendr√°s un backend modular, testeable y preparado para producci√≥n, sin sacrificar claridad ni mantenibilidad.**
